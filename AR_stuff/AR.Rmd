```{r include=FALSE, results='hide'}
# Install/import packages
if (!require(tidybayes)) {
    install.packages("tidybayes")
    library(tidybayes)
}

if (!require(forecast)) {
    install.packages("forecast")
    library(forecast)
}

if (!require(freqdom)) {
    install.packages("freqdom")
    library(freqdom)
}

if (!require(brms)) {
    install.packages("brms")
    library(brms)
}

if (!require(loo)) {
  install.packages("loo")
  library(loo)
}

if(!require(ggplot2)){
    install.packages("ggplot2")
    library(ggplot2)
}

if(!require(bayesplot)){
    install.packages("bayesplot")
    library(bayesplot)
}

if(!require(cmdstanr)){
    install.packages("cmdstanr", repos = c("https://mc-stan.org/r-packages/", getOption("repos")))
    library(cmdstanr)
}
cmdstan_installed <- function(){
  res <- try(out <- cmdstanr::cmdstan_path(), silent = TRUE)
  !inherits(res, "try-error")
}
if(!cmdstan_installed()){
    install_cmdstan()
}
```

```{r include=FALSE, results='hide'}
# General settings (e.g., seed, package options setting)
set.seed(42)
```

Some helper functions from the time series course
```{r}
# Define some helper functions

#' Plot autocorrelation and partial autocorrelation of time series
#'
#' @param data_ts Time series as a ts object.
#' @param lagmax Provides value for lag.max argument of acf and pacf.
plot_acf <- function(data_ts, lagmax = NULL) {
  par(mfrow = c(1, 2))
  acf(data_ts, main = "ACF", lag.max = lagmax)
  pacf(data_ts, main = "PACF", lag.max = lagmax)
  par(mfrow = c(1, 1))
}

#' Perform Ljung-Box test
#'
#' Calculates p-values for Ljung-Box test for lags {k+1, ..., n}, where k
#' is the number of model parameters.
#'
#' @param model Object of class Arima, represents the fitted model.
#' @param k Number of model parameters.
#' @param n Sample size (length of the time series).
#'
#' @return Vector of p-values.
box_test <- function(model, k, n) {
  pvalues <- c(rep(NA, n - k - 1))
  for (i in 1:(n - k - 1)) {
    pvalues[i] <- Box.test(model$res, lag = i + k, fitdf = k,
                           type = "Ljung-Box")$p.value
  }
  pvalues
}

#' Plot p-values from Ljung-box test for different lags
#'
#' @param pvalues Vector of p-values.
#' @param alpha Significance level.
#' @param k Number of model parameters.
#' @param n Sample size (length of the time series).
plot_pvalues <- function(pvalues, alpha, k, n) {
  plot((k + 1):(n - 1), pvalues, pch = 16, col = "midnightblue",
       ylim = c(0, max(pvalues)), xlab = "lag", ylab = "p-value")
  abline(h = alpha, lty = 2, lwd = 2)
}

#' Plot original time series and fitted model.
#'
#' @param data_ts Time series as ts object.
#' @param model Fitted time series model as Arima object.
#'
plot_fit <- function(data_ts, model) {
  fit <- model$fitted
  plot(fit, type = "b", col = "blue", ylab = "Value", xlab = "Time", cex = 0.5,
       pch = 16, main = "")
  lines(data_ts, col = "red", type = "b", cex = 0.5, pch = 16)
  legend("topleft", legend = c("Time series", "Fit"), col = c("red", "blue"),
         lty = c(1, 1), cex = 0.5)
}

#' Plot original time series and s-step prediction.
#'
#' @param data_ts Time series as ts object.
#' @param prediction S-step prediction as ts object.
plot_pred <- function(data_ts, prediction, title = "", xlim = NULL,
                      ylim = NULL) {
  plot(data_ts, col = "red", type = "b", cex = 0.5, pch = 16, ylab = "Value",
       xlab = "Time", main = title, xlim = xlim, ylim = ylim)
  lines(prediction, col = "blue", type = "b", cex = 0.5, pch = 16)
  legend("topleft", legend = c("Time series", "Prediction"),
         col = c("red", "blue"), lty = c(1, 1), cex = 0.5)
}
```

```{r}
library(readr)
combined <- read_csv("../data_processing/data/combined.csv")
names(combined) <- c("year", "renewable", "hydro", "wind", "wood", "other_renewable", "fossil", "oil", "coal", "gas", "peat", "other_fossil", "nuclear", "import", "other", "renewable_prod", "fossil_peat_prod", "nuclear_prod", "net_import", "others_prod", "renewable_gen", "co2", "co2_equivalent", "co2_lifecycle")
```

```{r}
ggplot(combined, aes(x = year, y = co2_lifecycle)) + 
  geom_point(size = 1) +
  labs(
    y = "CO2 coefficient", 
    x = "Year"
  ) 
```

```{r}
co2_ts_orig <- ts(combined$co2_lifecycle, start=combined$year[1], end=combined$year[length(combined$year)])
co2_ts <- co2_ts_orig
#co2_ts <- diff(co2_ts, differences=1)

plot(co2_ts)
plot_acf(co2_ts)
```
Seems that difference of 1 makes the series stationary, and the (2,2) model should work. 
```{r}
model <- Arima(co2_ts_orig, order=c(0,1,0), seasonal=c(0,0,0))
model
plot_fit(co2_ts_orig, model)
```
Not too good, but let's see how bayesian would do.

```{r}
#data <- data.frame(year=combined$year[-1], co2=co2_ts)
data <- combined
```

```{r}
formula <- bf(co2 ~ renewable_prod + ar(time = year, p=1), family="Gaussian")
get_prior(formula, data=data)
ar_priors <- c(
  prior(normal(0, 0.5), 
        class = "ar"),
  prior(normal(0, 2),
        coef="renewable_prod")
  )
```
```{r}
fit <- brm(formula = formula, prior = ar_priors, data=data, iter = 10000)
summary(fit)
```

```{r}
np <- nuts_params(fit)
mcmc_pairs(as.array(fit), np = np)
```
```{r}
preds <- posterior_predict(fit, ndraws=2000)
preds <- cbind(
  Estimate = colMeans(preds), 
  Q5 = apply(preds, 2, quantile, probs = 0.05),
  Q95 = apply(preds, 2, quantile, probs = 0.95)
)
ggplot(cbind(data, preds), aes(x = year, y = Estimate)) +
  geom_smooth(aes(ymin = Q5, ymax = Q95), stat = "identity", linewidth = 0.5) +
  geom_point(aes(y = co2)) + 
  labs(
    y = "co2", 
    x = "Year"
  ) 
```
```{r}
pp_check(fit, type="ribbon", ndraws=2000)
```

```{r}
pp_check(fit, type="loo_pit_qq", moment_match=TRUE, reloo=TRUE)
```

```{r}
pp_check(fit, ndraws=100)
```

```{r}
hist(predictive_error(fit))
```
```{r}
# some helper functions we'll use throughout

# more stable than log(sum(exp(x))) 
log_sum_exp <- function(x) {
  max_x <- max(x)  
  max_x + log(sum(exp(x - max_x)))
}

# more stable than log(mean(exp(x)))
log_mean_exp <- function(x) {
  log_sum_exp(x) - log(length(x))
}

# compute log of raw importance ratios
# sums over observations *not* over posterior samples
sum_log_ratios <- function(loglik, ids = NULL) {
  if (!is.null(ids)) loglik <- loglik[, ids, drop = FALSE]
  rowSums(loglik)
}

# for printing comparisons later
rbind_print <- function(...) {
  round(rbind(...), digits = 2)
}

lfo_M <- function(fit, L, M, data) {
  df <- data
  # L is the number of data points left in the beginning for training
  N <- length(data$co2)
  loo_cv <- loo(log_lik(fit)[, (L + 1):N])
  loglik_exact <- matrix(nrow = ndraws(fit), ncol = N)
  loglikm <- matrix(nrow = ndraws(fit), ncol = N)
for (i in L:(N - M)) {
  past <- 1:i
  oos <- (i + 1):(i + M)
  df_past <- df[past,]
  df_oos <- df[c(past, oos),]
  fit_past <- update(fit, newdata = df_past, recompile = FALSE, refresh=0)
  loglik <- log_lik(fit_past, newdata = df_oos, oos = oos)
  loglikm[, i + 1] <- rowSums(loglik[, oos])
}
  
  exact_elpds <- apply(loglikm, 2, log_mean_exp)
  (exact_elpd <- c(ELPD = sum(exact_elpds, na.rm = TRUE)))
  
  rbind_print(
    "LOO" = loo_cv$estimates["elpd_loo", "Estimate"],
    "LFO" = exact_elpd
  )
}
```
```{r}
pareto_lfo_M <- function(fit, L, M, data) {
  df <- data
  plot_ks <- function(ks, ids, thres = 0.6) {
  dat_ks <- data.frame(ks = ks, ids = ids)
  ggplot(dat_ks, aes(x = ids, y = ks)) + 
    geom_point(aes(color = ks > thres), shape = 3, show.legend = FALSE) + 
    geom_hline(yintercept = thres, linetype = 2, color = "red2") + 
    scale_color_manual(values = c("cornflowerblue", "darkblue")) + 
    labs(x = "Data point", y = "Pareto k") + 
    ylim(-0.5, 1.5)
}
  
  N <- length(data$co2)
  loo_cv <- loo(log_lik(fit)[, (L + 1):N])
  k_thres <- 0.7
  approx_elpds_4sap <- rep(NA, N)

  past <- 1:L
  oos <- (L + 1):(L + M)
  df_past <- df[past,]
  df_oos <- df[c(past, oos),]
  fit_past <- update(fit, newdata = df_past, recompile = FALSE, refresh =0)
  loglik <- log_lik(fit_past, newdata = df_oos, oos = oos)
  loglikm <- rowSums(loglik[, oos])
  approx_elpds_4sap[L + 1] <- log_mean_exp(loglikm)
  
  # iterate over i > L
  i_refit <- L
  refits <- L
  ks <- NULL
  for (i in (L + 1):(N - M)) {
    past <- 1:i
    oos <- (i + 1):(i + M)
    df_past <- df[past, ]
    df_oos <- df[c(past, oos),]
    loglik <- log_lik(fit_past, newdata = df_oos, oos = oos)
    
    logratio <- sum_log_ratios(loglik, (i_refit + 1):i)
    psis_obj <- suppressWarnings(psis(logratio))
    k <- pareto_k_values(psis_obj)
    ks <- c(ks, k)
    if (k > k_thres) {
      # refit the model based on the first i observations
      i_refit <- i
      refits <- c(refits, i)
      fit_past <- update(fit_past, newdata = df_past, recompile = FALSE, refresh=0)
      loglik <- log_lik(fit_past, newdata = df_oos, oos = oos)
      loglikm <- rowSums(loglik[, oos])
      approx_elpds_4sap[i + 1] <- log_mean_exp(loglikm)
    } else {
      lw <- weights(psis_obj, normalize = TRUE)[, 1]
      loglikm <- rowSums(loglik[, oos])
      approx_elpds_4sap[i + 1] <- log_sum_exp(lw + loglikm)
    }
  } 
    approx_elpd <- sum(approx_elpds_4sap, na.rm = TRUE)
    cat(
    "approx LFO ", approx_elpd, "\n"
    )
    cat("Using threshold ", k_thres, 
      ", model was refit ", length(refits), 
      " times, at observations", refits)
    plot_ks(ks, (L + 1):(N - M))
}
```

```{r}
lfo_M(fit, 5, 2, data)
```
```{r}
pareto_lfo_M(fit, 5, 2, data)
```
```{r}
lfo <- function(fit, L, data) {
  df <- data
  # L is the number of data points left in the beginning for training
  N <- length(data$co2)
  loo_cv <- loo(log_lik(fit)[, (L + 1):N])
  loglik_exact <- matrix(nrow = ndraws(fit), ncol = N)
for (i in L:(N - 1)) {
  past <- 1:i
  oos <- i + 1
  df_past <- df[past, ]
  df_oos <- df[c(past, oos),]
  fit_i <- update(fit, newdata = df_past, recompile = FALSE, refresh=0)
  loglik_exact[, i + 1] <- log_lik(fit_i, newdata = df_oos, oos = oos)[, oos]
}
  
  exact_elpds <- apply(loglik_exact, 2, log_mean_exp)
  (exact_elpd <- c(ELPD = sum(exact_elpds, na.rm = TRUE)))
  
  rbind_print(
    "LOO" = loo_cv$estimates["elpd_loo", "Estimate"],
    "LFO" = exact_elpd
  )
}
```

```{r}
pareto_lfo <- function(fit, L, data) {
  M <- 1
  df <- data
  plot_ks <- function(ks, ids, thres = 0.6) {
  dat_ks <- data.frame(ks = ks, ids = ids)
  ggplot(dat_ks, aes(x = ids, y = ks)) + 
    geom_point(aes(color = ks > thres), shape = 3, show.legend = FALSE) + 
    geom_hline(yintercept = thres, linetype = 2, color = "red2") + 
    scale_color_manual(values = c("cornflowerblue", "darkblue")) + 
    labs(x = "Data point", y = "Pareto k") + 
    ylim(-0.5, 1.5)
}
  
  N <- length(data$co2)
  loo_cv <- loo(log_lik(fit)[, (L + 1):N])
  k_thres <- 0.7
  approx_elpds_1sap <- rep(NA, N)

# initialize the process for i = L
past <- 1:L
oos <- L + 1
df_past <- df[past,]
df_oos <- df[c(past, oos),]
fit_past <- update(fit, newdata = df_past, recompile = FALSE, refresh=0)
loglik <- log_lik(fit_past, newdata = df_oos, oos = oos)
approx_elpds_1sap[L + 1] <- log_mean_exp(loglik[, oos])

# iterate over i > L
i_refit <- L
refits <- L
ks <- NULL
for (i in (L + 1):(N - 1)) {
  past <- 1:i
  oos <- i + 1
  df_past <- df[past,]
  df_oos <- df[c(past, oos),]
  loglik <- log_lik(fit_past, newdata = df_oos, oos = oos)
  
  logratio <- sum_log_ratios(loglik, (i_refit + 1):i)
  psis_obj <- suppressWarnings(psis(logratio))
  k <- pareto_k_values(psis_obj)
  ks <- c(ks, k)
  if (k > k_thres) {
    # refit the model based on the first i observations
    i_refit <- i
    refits <- c(refits, i)
    fit_past <- update(fit_past, newdata = df_past, recompile = FALSE, refresh=0)
    loglik <- log_lik(fit_past, newdata = df_oos, oos = oos)
    approx_elpds_1sap[i + 1] <- log_mean_exp(loglik[, oos])
  } else {
    lw <- weights(psis_obj, normalize = TRUE)[, 1]
    approx_elpds_1sap[i + 1] <- log_sum_exp(lw + loglik[, oos])
  }
} 
    approx_elpd <- sum(approx_elpds_1sap, na.rm = TRUE)
    cat(
    "approx LFO ", approx_elpd, "\n"
    )
    cat("Using threshold ", k_thres, 
      ", model was refit ", length(refits), 
      " times, at observations", refits)
    plot_ks(ks, (L + 1):(N - M))
}
```

```{r}
lfo(fit, 5, data)
```
```{r}
pareto_lfo(fit, 5, data)
```